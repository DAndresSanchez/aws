{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca22d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54266e3b",
   "metadata": {},
   "source": [
    "We will use a Kaggle dataset about credit card fraud detection. This dataset consists of transactions made by credit cards in September 2013 by European cardholders.\n",
    "It contains 492 frauds out of a total of 284,807 transactions. You can see that it is highly unbalanced, where the positive class (frauds) account for 0.172% of all transactions. https://www.kaggle.com/datasets/whenamancodes/fraud-detection\n",
    "The objective of this article is illustrate how to train a built-in model like XGBoost in an AWS Sagemaker's notebook instance. In this case a supervised learning, specifically a binary classification problem.\n",
    "\n",
    "But first, what do I mean by built-in algorithms? Amazon SageMaker provides several built-in algorithms that you can use to train your models. These algorithms are highly optimized, scalable, and designed to generate accurate models rapidly, eliminating the need to create and maintain the underlying algorithm containers, thus saving time and resources.\n",
    "\n",
    "Let's start by importing the basic python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e145507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfb87f",
   "metadata": {},
   "source": [
    "We use pandas to read the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "840709c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f0d19",
   "metadata": {},
   "source": [
    "We should do an Exploratory Data Analysis here, howerver we will skip it for brevity. We will drop the feature \"Time\" and will retain the rest of anonymised credit card related features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f20ce16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df1cf81",
   "metadata": {},
   "source": [
    "Let's check the number of transactions belonging to each class (Fraud or Normal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "922da980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ee8c2",
   "metadata": {},
   "source": [
    "It is heavily imbalanced. Since this article aims to focus on the Sagemaker side, we won't try to optimise the model to get the best possible result. Therefore, let's just undersample randomly the majority class. We will take randomly the same number of transactions that we have in the normal ones, i.e. 492."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "abf67159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud transactions\n",
    "df_1 = df[df.Class == 1]\n",
    "\n",
    "# Undersampled normal transactions\n",
    "df_0 = df[df.Class == 0].sample(df_1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d7207",
   "metadata": {},
   "source": [
    "Now we concatenate both datasets and reset the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1656fb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.876591</td>\n",
       "      <td>-0.155384</td>\n",
       "      <td>0.361307</td>\n",
       "      <td>0.987282</td>\n",
       "      <td>-0.045266</td>\n",
       "      <td>0.446142</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.193986</td>\n",
       "      <td>-0.276750</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109980</td>\n",
       "      <td>0.132488</td>\n",
       "      <td>-0.060499</td>\n",
       "      <td>-0.278848</td>\n",
       "      <td>0.303804</td>\n",
       "      <td>-0.436598</td>\n",
       "      <td>0.034929</td>\n",
       "      <td>0.031098</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.670310</td>\n",
       "      <td>0.803298</td>\n",
       "      <td>2.078889</td>\n",
       "      <td>0.397425</td>\n",
       "      <td>0.464632</td>\n",
       "      <td>-0.511305</td>\n",
       "      <td>1.025419</td>\n",
       "      <td>-0.186385</td>\n",
       "      <td>-0.195366</td>\n",
       "      <td>-0.615139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028493</td>\n",
       "      <td>0.232540</td>\n",
       "      <td>-0.238697</td>\n",
       "      <td>0.606070</td>\n",
       "      <td>0.209983</td>\n",
       "      <td>-0.525307</td>\n",
       "      <td>-0.058154</td>\n",
       "      <td>-0.116236</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.955515</td>\n",
       "      <td>-0.577371</td>\n",
       "      <td>-0.083715</td>\n",
       "      <td>0.242985</td>\n",
       "      <td>-0.553677</td>\n",
       "      <td>0.599422</td>\n",
       "      <td>-1.221767</td>\n",
       "      <td>0.295218</td>\n",
       "      <td>2.577602</td>\n",
       "      <td>-0.207888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103016</td>\n",
       "      <td>-0.019276</td>\n",
       "      <td>0.312469</td>\n",
       "      <td>0.158574</td>\n",
       "      <td>-0.622843</td>\n",
       "      <td>0.425357</td>\n",
       "      <td>-0.052634</td>\n",
       "      <td>-0.053608</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.189870</td>\n",
       "      <td>1.321957</td>\n",
       "      <td>0.471306</td>\n",
       "      <td>2.477934</td>\n",
       "      <td>0.081151</td>\n",
       "      <td>0.793808</td>\n",
       "      <td>-0.133616</td>\n",
       "      <td>0.991140</td>\n",
       "      <td>-1.147900</td>\n",
       "      <td>1.202786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100378</td>\n",
       "      <td>0.301430</td>\n",
       "      <td>-0.268094</td>\n",
       "      <td>-0.268996</td>\n",
       "      <td>0.310630</td>\n",
       "      <td>0.188044</td>\n",
       "      <td>-1.377141</td>\n",
       "      <td>-0.330257</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.444927</td>\n",
       "      <td>0.364529</td>\n",
       "      <td>-0.698316</td>\n",
       "      <td>0.780500</td>\n",
       "      <td>-0.263478</td>\n",
       "      <td>0.549751</td>\n",
       "      <td>1.026421</td>\n",
       "      <td>0.288750</td>\n",
       "      <td>-1.271627</td>\n",
       "      <td>-0.061335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549802</td>\n",
       "      <td>1.131155</td>\n",
       "      <td>0.402189</td>\n",
       "      <td>0.366272</td>\n",
       "      <td>-0.544862</td>\n",
       "      <td>1.108977</td>\n",
       "      <td>-0.038090</td>\n",
       "      <td>0.136139</td>\n",
       "      <td>255.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.876591 -0.155384  0.361307  0.987282 -0.045266  0.446142  0.007623   \n",
       "1 -0.670310  0.803298  2.078889  0.397425  0.464632 -0.511305  1.025419   \n",
       "2  1.955515 -0.577371 -0.083715  0.242985 -0.553677  0.599422 -1.221767   \n",
       "3 -3.189870  1.321957  0.471306  2.477934  0.081151  0.793808 -0.133616   \n",
       "4 -0.444927  0.364529 -0.698316  0.780500 -0.263478  0.549751  1.026421   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.193986 -0.276750  0.004941  ...  0.109980  0.132488 -0.060499 -0.278848   \n",
       "1 -0.186385 -0.195366 -0.615139  ... -0.028493  0.232540 -0.238697  0.606070   \n",
       "2  0.295218  2.577602 -0.207888  ... -0.103016 -0.019276  0.312469  0.158574   \n",
       "3  0.991140 -1.147900  1.202786  ...  0.100378  0.301430 -0.268094 -0.268996   \n",
       "4  0.288750 -1.271627 -0.061335  ...  0.549802  1.131155  0.402189  0.366272   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.303804 -0.436598  0.034929  0.031098  120.00      0  \n",
       "1  0.209983 -0.525307 -0.058154 -0.116236    1.00      0  \n",
       "2 -0.622843  0.425357 -0.052634 -0.053608   14.95      0  \n",
       "3  0.310630  0.188044 -1.377141 -0.330257    1.00      0  \n",
       "4 -0.544862  1.108977 -0.038090  0.136139  255.33      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bal = pd.concat((df_0, df_1), axis=0)\n",
    "df_bal.reset_index(drop=True, inplace=True)\n",
    "df_bal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3785a1",
   "metadata": {},
   "source": [
    "Before continuing, since we are going to use XGBoost, which is a decision tree based algorithm, we don't necessarily need to scale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850e0d1",
   "metadata": {},
   "source": [
    "#### Split into training, validation and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb437f",
   "metadata": {},
   "source": [
    "First, we need to split into features (X) and target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14a46d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bal.iloc[:,:-1]\n",
    "y = df_bal.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985bce8",
   "metadata": {},
   "source": [
    "Now, using sklearn function train_test_split, we can split our data into the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "896b8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c4bbc",
   "metadata": {},
   "source": [
    "We use 10% of the data as a testing set. Also, note that we use the argument `stratify`. This is to ensure that each set contains approximately the same percentage of samples of each target class as the complete set (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca59239d",
   "metadata": {},
   "source": [
    "Since we want a validation set too, we will further split the training set. Again allocating 10%, this time as validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e97036b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.1, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80219f",
   "metadata": {},
   "source": [
    "We can have a look at the size of each set to verify that we have carried that over correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d2a7a74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885, 99, 89)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_test.shape[0], X_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3af3a9",
   "metadata": {},
   "source": [
    "Amazon S3 bucket, part of AWS's Simple Storage Service (S3), is a scalable cloud storage solution providing object storage, allowing users to store and retrieve data in units termed as objects, instead of traditional file systems. Each object within the S3 bucket is identified with a unique, user-assigned key, ensuring precise data retrieval.\n",
    "\n",
    "We will create an S3 bucket where we will store our model files. The prefix refers to the subdirectories or subfolders where the files will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4a32f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-test-david'\n",
    "prefix = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07a5a8f",
   "metadata": {},
   "source": [
    "Sagemaker built-in algorithms require datasets where the first feature is the label or target (y) and the rest of them are the independent variables (X). For the training and validation sets to be used by the algorithms, we need to upload them to an S3 bucket in a special way.\n",
    "\n",
    "First, let's create a Sagemaker session in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eec8fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50e2ab",
   "metadata": {},
   "source": [
    "We need to concatenate the y and X to create the dataset in the expected format and order and save it locally as a csv file. Afterwards we need to upload it to a specific S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3739d014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-test-david/test/validation/validation.csv'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "pd.concat([y_train, X_train], axis=1).to_csv('train.csv', \n",
    "                                             index=False, \n",
    "                                             header=False)\n",
    "sess.upload_data(path='train.csv', \n",
    "                 bucket=bucket, \n",
    "                 key_prefix=prefix+'/train')\n",
    "\n",
    "# Validation set\n",
    "pd.concat([y_val, X_val], axis=1).to_csv('validation.csv', \n",
    "                                         index=False, \n",
    "                                         header=False)\n",
    "sess.upload_data(path='validation.csv', \n",
    "                 bucket=bucket, \n",
    "                 key_prefix=prefix+'/validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b223c5a",
   "metadata": {},
   "source": [
    "Next, we use he Sagemaker's `TrainingInput` class to configure a data input flow for training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b08e6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# Training set\n",
    "s3_input_train = TrainingInput(s3_data=f's3://{bucket}/{prefix}/train', \n",
    "                               content_type='csv')\n",
    "\n",
    "# Validation set\n",
    "s3_input_validation = TrainingInput(s3_data=f's3://{bucket}/{prefix}/validation/', \n",
    "                                    content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5c353",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e594bf",
   "metadata": {},
   "source": [
    "Time to train our model. In this stage we need to import our built-in algorithm. \n",
    "\n",
    "Before that, we will need the following information:\n",
    "* region: the AWS Region where the SageMaker notebook instance is running (eu-west-2, eu-central-1, us-east-1...).\n",
    "* session: the SageMaker session that holds the configuration and is used to create all the needed AWS resources like training jobs, endpoints, etc.\n",
    "* role: the IAM Role ARN used to give training and deployment access to your data. You usually get this role when you create a notebook instance unless specified otherwise.\n",
    "* instance type: is the type of EC2 instance used for training your model, such as \"ml.m4.xlarge\", \"ml.m5.large\", etc. You'll need to carefully choose the optimal for your case, checking parameters like memory, CPU and, of course, price per hour. https://aws.amazon.com/sagemaker/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b9106a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "instance_type = 'ml.m4.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8718e0",
   "metadata": {},
   "source": [
    "Next, we need to retrieve the container image URI for the specified built-in algorithm or model, in this case XGBoost. Each built-in algorithm or pre-built model in SageMaker is stored in a Docker container, and this container is located at a specific URI (Uniform Resource Identifier).\n",
    "\n",
    "When you are creating an estimator, you need to specify the location (URI) of the Docker container that has the algorithm or model. The image_uris.retrieve function simplifies this process by generating the correct URI for you based on the algorithm or model, region, and other parameters you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "70899226",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(framework=\"xgboost\", \n",
    "                                          region=region, \n",
    "                                          version=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2278a",
   "metadata": {},
   "source": [
    "An Estimator is an abstraction represented by the Estimator class in the SageMaker Python SDK, which allows users to train machine learning models. It encapsulates the training job and its associated configurations, such as the algorithm container, training data, hyperparameters, and compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "03c815c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "xgb = Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    sagemaker_session=sess,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    input_mode='File',\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    train_use_spot_instance=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4eb9ab",
   "metadata": {},
   "source": [
    "Let's explain some of the arguments we set:\n",
    "* instance_count: The number of Amazon EC2 instances you want to use for training. 1 indicates a single instance.\n",
    "* input_mode: The input mode that the algorithm supports. \"File\" mode means the training data is transferred to the training instances using Amazon S3.\n",
    "* output_path: The S3 location for saving the training results (model artifacts and output files).\n",
    "* train_use_spot_instance: This argument suggests using EC2 Spot Instances for training, which can significantly reduce the cost of training models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25285aaa",
   "metadata": {},
   "source": [
    "We need to set up also the hyperparameters. These are some of the hyperparameters you can set up:\n",
    "* alpha: The L1 regularization term on weights, used to avoid overfitting.\n",
    "* eta: The learning rate, controlling the contribution of each tree in the ensemble.\n",
    "* gamma: The minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "* max_depth: The maximum depth of a tree, controlling overfitting.\n",
    "* min_child_weight: The minimum sum of instance weight needed in a child, used to control overfitting.\n",
    "* subsample: The fraction of training data to randomly sample in each round to prevent overfitting.\n",
    "* objective: The learning task and the corresponding learning objective. Here, we chose binary classification with logistic regression.\n",
    "* num_round: The number of boosting rounds or trees to build, equivalent to the number of models in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "35ec3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(\n",
    "    alpha=1.5,\n",
    "    eta=0.1,\n",
    "    gamma=4,\n",
    "    max_depth=2,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    num_round=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b220be",
   "metadata": {},
   "source": [
    "Finally, time to fit our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "61a8270f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-22 15:28:25 Starting - Starting the training job...\n",
      "2023-09-22 15:28:51 Starting - Preparing the instances for trainingProfilerReport-1695396505: InProgress\n",
      "......\n",
      "2023-09-22 15:29:51 Downloading - Downloading input data...\n",
      "2023-09-22 15:30:16 Training - Downloading the training image...\n",
      "2023-09-22 15:30:56 Training - Training image download completed. Training in progress...\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2023-09-22:15:31:01:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2023-09-22:15:31:01:INFO] File size need to be processed in the node: 0.5mb. Available memory size in the node: 254.8mb\u001b[0m\n",
      "\u001b[34m[2023-09-22:15:31:01:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:31:01] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:31:01] 885x29 matrix with 25665 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2023-09-22:15:31:01:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:31:01] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:31:01] 89x29 matrix with 2581 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.080226#011validation-error:0.033708\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.080226#011validation-error:0.067416\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.079096#011validation-error:0.089888\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.076836#011validation-error:0.067416\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.072316#011validation-error:0.044944\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.071186#011validation-error:0.067416\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.068927#011validation-error:0.067416\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.065537#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.064407#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.063277#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.066667#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.066667#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.066667#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.062147#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.057627#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.057627#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.057627#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.058757#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.056497#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.058757#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.056497#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.056497#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.057627#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.056497#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.053107#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.053107#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.051977#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.053107#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.051977#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.053107#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.054237#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.053107#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.053107#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.051977#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.051977#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.051977#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.051977#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.051977#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.051977#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.053107#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.049718#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.049718#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.050847#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.049718#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.049718#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.047458#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.047458#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.047458#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.047458#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.047458#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.047458#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.047458#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.046328#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.046328#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.046328#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.046328#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.046328#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.045198#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\u001b[34m[15:31:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.044068#011validation-error:0.05618\u001b[0m\n",
      "\n",
      "2023-09-22 15:31:17 Uploading - Uploading generated training model\n",
      "2023-09-22 15:31:17 Completed - Training job completed\n",
      "Training seconds: 102\n",
      "Billable seconds: 102\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd845b",
   "metadata": {},
   "source": [
    "#### Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f17c2",
   "metadata": {},
   "source": [
    "Time to deploy the trained model so it can be used in production. We need to select the instance type and count depending our requirements. Also the model and endpoint names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "14250dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'prs-test-3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "284a529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# create endpoint and predictor\n",
    "xgb_predictor = xgb.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    model_name=model_name,\n",
    "    endpoint_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25883a8",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6b5dd",
   "metadata": {},
   "source": [
    "Before getting the predictions, we need to specify the serialization format that the SageMaker Predictor will use when sending data to our model endpoint. In this case, we'll be using the CSVSerializer, meaning that the predictor will serialize the input data to CSV format before sending it to the model endpoint for inference. Serialization is the process of converting a data structure or object state into a format that can be easily stored or transmitted, and subsequently reconstructed. In other words, it's about translating complex data types such as objects or structures into a format (like a string) that can be easily rendered into a file, sent over the network, or saved into a database. Once the serialized data reaches its destination, it can be deserialized back into its original format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e47153ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import CSVSerializer \n",
    "xgb_predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080033f",
   "metadata": {},
   "source": [
    "Time to get the predictions for our testing set. We use the method `predict` of our deployed predictor. However, this method requires the data to be in a numpy array format, not in a pandas Dataframe. Finally, we need to decode the output and convert it to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "92bf74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_predictor.predict(X_test.values)\n",
    "y_pred = np.fromstring(predictions.decode('utf-8'), sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c3bb1",
   "metadata": {},
   "source": [
    "Now we can assess the performance of the model. Since our test data was balanced at the beginning, we will calculate the accuracy for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8acc89cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 94.95%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred.round() == y_test).sum() / y_test.shape[0] * 100\n",
    "print(f'The accuracy of the model is {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9639d",
   "metadata": {},
   "source": [
    "We can also see the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f16be0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  1]\n",
      " [ 4 45]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53111c",
   "metadata": {},
   "source": [
    "This was a toy dataset and it was possibly highly preprocessed. Therefore the result is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52383cbe",
   "metadata": {},
   "source": [
    "#### Create predictor from endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c4036b",
   "metadata": {},
   "source": [
    "Imagine you created your model and endpoint in the past and you want to test some data in a notebook. You could load your endpoint in a predictor and do the same as we've just done when assessing the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "221a1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "# Load endpoint\n",
    "predictor = Predictor(\n",
    "    endpoint_name=model_name,\n",
    ")\n",
    "\n",
    "# Set serialization to CSV\n",
    "predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59348bd",
   "metadata": {},
   "source": [
    "Get the predictions as done before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a79c104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(X_test.values)\n",
    "y_pred = np.fromstring(predictions.decode('utf-8'), sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805285dc",
   "metadata": {},
   "source": [
    "The next step would be to make the endpoint available for a production environment. You can achieve this using an AWS Lambda Function and creating an API from it. We will cover this in future articles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
